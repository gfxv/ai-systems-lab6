{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "-xNa7gVn-aHh"
   },
   "outputs": [],
   "source": [
    "# task 5\n",
    "import numpy as np\n",
    "\n",
    "# Максимизация правдоподобия\n",
    "\n",
    "class LogisticRegression:\n",
    "  def __init__(self, bias=False, iterations = 1000, learning_rate = 0.01):\n",
    "    self.bias, self.iterations, self.learning_rate = bias, iterations, learning_rate\n",
    "    self.sigmoid = lambda z : 1 / (1 + np.exp(-z))\n",
    "    self.gradient = lambda x, y, coef_ : x.T @ (self.sigmoid(x @ coef_) - y)\n",
    "\n",
    "  def get_params(self):\n",
    "    return {\n",
    "        'learning_rate': self.learning_rate,\n",
    "        'iterations': self.iterations,\n",
    "        'bias': self.bias\n",
    "    }\n",
    "\n",
    "  def set_params(self, **params):\n",
    "      for key, value in params.items():\n",
    "          setattr(self, key, value)\n",
    "      return self\n",
    "\n",
    "  def log_loss(self, x, y):\n",
    "    y_pred = self.sigmoid( x @ self.coef_)\n",
    "    return -(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred)).mean()\n",
    "\n",
    "  def fit(self, x, y):\n",
    "    if self.bias: \n",
    "      np.insert(x, 0, 1, axis=1)\n",
    "    self.coef_ = np.zeros_like(x[0])\n",
    "\n",
    "    for _ in range(self.iterations):\n",
    "      self.coef_ -= self.learning_rate * self.gradient(x, y, self.coef_)\n",
    "    return self\n",
    "\n",
    "  def predict(self, x):\n",
    "    if self.bias: \n",
    "      np.insert(x, 0, 1, axis=1)\n",
    "    return np.where(self.sigmoid(x @ self.coef_) > 0.5, 1, 0)\n",
    "\n",
    "  def clone(self):\n",
    "    return LogisticRegression(self.bias, self.iterations, self.learning_rate)\n",
    "\n",
    "  def statistics(self, x, y):\n",
    "    out = self.predict(x)\n",
    "    outputs = {'False': 1, 'True': 0}\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for out_i, y_i in zip(out, y):\n",
    "      if out_i == outputs['True']:\n",
    "        if y_i == outputs['True']:\n",
    "          tp += 1\n",
    "        else:\n",
    "          fp += 1\n",
    "      else:\n",
    "        if y_i == outputs['True']:\n",
    "          fn += 1\n",
    "        else:\n",
    "          tn += 1\n",
    "    return {'TP': tp, 'TN': tn, 'FP': fp, 'FN': fn}\n",
    "\n",
    "  def score(self, x, y):\n",
    "    stats = self.statistics(x, y)\n",
    "    return (stats['TP'] + stats['TN']) / (stats['TP'] + stats['TN'] + stats['FP'] + stats['FN'])\n",
    "\n",
    "  def accuracy(self, x, y):\n",
    "    stats = self.statistics(x, y)\n",
    "    return (stats['TP'] + stats['TN']) / (stats['TP'] + stats['TN'] + stats['FP'] + stats['FN'])\n",
    "\n",
    "  def precision(self, x, y):\n",
    "    stats = self.statistics(x, y)\n",
    "    return stats['TP'] / (stats['TP'] + stats['FP'])\n",
    "\n",
    "  def recall(self, x, y):\n",
    "    stats = self.statistics(x, y)\n",
    "    return stats['TP'] / (stats['TP'] + stats['FN'])\n",
    "\n",
    "  def f1_score(self, x, y):\n",
    "    precision = self.precision(x, y)\n",
    "    recall = self.recall(x, y)\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "  def confusion_matrix(self, x, y):\n",
    "    stats = self.statistics(x, y)\n",
    "    return np.array([[stats['TN'], stats['FP']], [stats['FN'], stats['TP']]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "3PII9w3IK0IV"
   },
   "outputs": [],
   "source": [
    "class LogisticRegressionNewton(LogisticRegression):\n",
    "  def __init__(self, bias=False, iterations = 10000):\n",
    "    super().__init__(bias, iterations)\n",
    "    self.hessian = lambda x, coef_: x.T @ np.diag(self.sigmoid(x @ coef_) * (1 - self.sigmoid(x @ coef_))) @ x\n",
    "\n",
    "  def fit(self,x,y):\n",
    "    if self.bias: \n",
    "      np.insert(x, 0, 1, axis=1)\n",
    "    self.coef_ = np.zeros_like(x[0])\n",
    "    for _ in range(self.iterations):\n",
    "      self.coef_ -= np.linalg.pinv(self.hessian(x, self.coef_)) @ self.gradient(x, y, self.coef_)\n",
    "    return self\n",
    "\n",
    "  def get_params(self, deep=True):\n",
    "    return {\n",
    "        'iterations': self.iterations,\n",
    "        'bias': self.bias\n",
    "    }\n",
    "\n",
    "  def clone(self):\n",
    "    return LogisticRegressionNewton(self.bias, self.iterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "YQf6oTpD80l_"
   },
   "outputs": [],
   "source": [
    "class LogisticRegressionAdaDelta(LogisticRegression):\n",
    "  def __init__(self, bias=False, iterations = 10000, epsilon = 1e-8):\n",
    "    super().__init__(bias, iterations)\n",
    "    self.epsilon = epsilon\n",
    "\n",
    "  def fit(self, x, y):\n",
    "    if self.bias: \n",
    "      np.insert(x, 0, 1, axis=1)\n",
    "    self.coef_ = np.zeros_like(x[0])\n",
    "    G = np.zeros_like(x[0])\n",
    "\n",
    "    for _ in range(self.iterations):\n",
    "      grad  = self.gradient(x, y, self.coef_)\n",
    "      G += grad ** 2\n",
    "      adaptive_lr = self.learning_rate / (np.sqrt(G) + self.epsilon)\n",
    "      self.coef_ -= adaptive_lr * grad\n",
    "    return self\n",
    "\n",
    "  def get_params(self, deep=True):\n",
    "    return {\n",
    "        'iterations': self.iterations,\n",
    "        'bias': self.bias,\n",
    "        'epsilon': self.epsilon\n",
    "    }\n",
    "\n",
    "  def clone(self):\n",
    "    return LogisticRegressionAdaDelta(self.bias, self.iterations, self.epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "i42XQKiO6AA0"
   },
   "outputs": [],
   "source": [
    "#task 1-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "o9LLT2ZlMGyR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "-gxoA2qNMSfw"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./train.csv\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "OPdmx_nQ-TOZ",
    "outputId": "a483e444-d45c-40b1-ae9e-07a6d9d29ff2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "1            2         1       1   \n",
       "3            4         1       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "\n",
       "   Parch    Ticket     Fare Cabin Embarked  \n",
       "1      0  PC 17599  71.2833   C85        C  \n",
       "3      0    113803  53.1000  C123        S  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "IFgW6HzB-W-K",
    "outputId": "ba044498-b1c0-472a-b2cc-3ab0cf00fafb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>183.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>183.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>455.366120</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>1.191257</td>\n",
       "      <td>35.674426</td>\n",
       "      <td>0.464481</td>\n",
       "      <td>0.475410</td>\n",
       "      <td>78.682469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>247.052476</td>\n",
       "      <td>0.470725</td>\n",
       "      <td>0.515187</td>\n",
       "      <td>15.643866</td>\n",
       "      <td>0.644159</td>\n",
       "      <td>0.754617</td>\n",
       "      <td>76.347843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>263.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>457.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>676.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>890.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   183.000000  183.000000  183.000000  183.000000  183.000000   \n",
       "mean    455.366120    0.672131    1.191257   35.674426    0.464481   \n",
       "std     247.052476    0.470725    0.515187   15.643866    0.644159   \n",
       "min       2.000000    0.000000    1.000000    0.920000    0.000000   \n",
       "25%     263.500000    0.000000    1.000000   24.000000    0.000000   \n",
       "50%     457.000000    1.000000    1.000000   36.000000    0.000000   \n",
       "75%     676.000000    1.000000    1.000000   47.500000    1.000000   \n",
       "max     890.000000    1.000000    3.000000   80.000000    3.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  183.000000  183.000000  \n",
       "mean     0.475410   78.682469  \n",
       "std      0.754617   76.347843  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000   29.700000  \n",
       "50%      0.000000   57.000000  \n",
       "75%      1.000000   90.000000  \n",
       "max      4.000000  512.329200  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "iEKKX0QfNkcN"
   },
   "outputs": [],
   "source": [
    "data[\"Cabin\"] = data[\"Cabin\"].apply(lambda x: x.split()[0][0])\n",
    "x = pd.get_dummies(data.drop(columns = [\"Name\" ,\"Ticket\", \"Survived\"]), columns=[\"Cabin\",\"Sex\",\"Embarked\"]).astype(float).values\n",
    "y = data[\"Survived\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "opxxzzOv2vDB"
   },
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    n_samples = len(X)\n",
    "    n_test = int(n_samples * test_size)\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    test_indices = indices[:n_test]\n",
    "    train_indices = indices[n_test:]\n",
    "    X_train, X_test = X[train_indices], X[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "zv-oPsfq24MI"
   },
   "outputs": [],
   "source": [
    "def cross_val_score(model, x, y, cv = 5):\n",
    "  estimator = model.clone()\n",
    "  scores = list()\n",
    "  for _ in range(cv):\n",
    "    estimator = model.clone()\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "    estimator.fit(x_train, y_train)\n",
    "    scores.append(estimator.score(x_test, y_test))\n",
    "  return scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "KjZk3z_d4n8j"
   },
   "outputs": [],
   "source": [
    "\n",
    "def grid_search_custom(model, param_grid, X, y, cv=5):\n",
    "    from itertools import product\n",
    "    param_combinations = list(product(*param_grid.values()))\n",
    "    param_names = list(param_grid.keys())\n",
    "    dct = dict()\n",
    "\n",
    "    for params in param_combinations:\n",
    "        param_dict = dict(zip(param_names, params))\n",
    "\n",
    "        model.set_params(**param_dict)\n",
    "\n",
    "        scores = cross_val_score(model, X, y, cv=cv)\n",
    "        mean_score = np.mean(scores)\n",
    "        dct[params] = (model, mean_score)\n",
    "    return dct\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8VfM3a2F74TC",
    "outputId": "4f86bf70-1bdd-4e77-d3f4-965cefb1003e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pl/zhkjndkn2k169_3t63dgk06m0000gn/T/ipykernel_10008/3618153951.py:9: RuntimeWarning: overflow encountered in exp\n",
      "  self.sigmoid = lambda z : 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{(0.1, 100): (<__main__.LogisticRegression at 0x10ff21a90>,\n",
       "  np.float64(0.6055555555555555)),\n",
       " (0.1, 200): (<__main__.LogisticRegression at 0x10ff21a90>,\n",
       "  np.float64(0.5944444444444444)),\n",
       " (0.1, 500): (<__main__.LogisticRegression at 0x10ff21a90>,\n",
       "  np.float64(0.6722222222222223)),\n",
       " (0.1, 1000): (<__main__.LogisticRegression at 0x10ff21a90>,\n",
       "  np.float64(0.5611111111111111)),\n",
       " (0.01, 100): (<__main__.LogisticRegression at 0x10ff21a90>,\n",
       "  np.float64(0.4833333333333334)),\n",
       " (0.01, 200): (<__main__.LogisticRegression at 0x10ff21a90>,\n",
       "  np.float64(0.6277777777777779)),\n",
       " (0.01, 500): (<__main__.LogisticRegression at 0x10ff21a90>,\n",
       "  np.float64(0.5111111111111112)),\n",
       " (0.01, 1000): (<__main__.LogisticRegression at 0x10ff21a90>,\n",
       "  np.float64(0.5333333333333333)),\n",
       " (0.001, 100): (<__main__.LogisticRegression at 0x10ff21a90>,\n",
       "  np.float64(0.6555555555555556)),\n",
       " (0.001, 200): (<__main__.LogisticRegression at 0x10ff21a90>,\n",
       "  np.float64(0.6055555555555555)),\n",
       " (0.001, 500): (<__main__.LogisticRegression at 0x10ff21a90>,\n",
       "  np.float64(0.6722222222222222)),\n",
       " (0.001, 1000): (<__main__.LogisticRegression at 0x10ff21a90>,\n",
       "  np.float64(0.7055555555555555))}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "param_grid = {\n",
    "    'lerning_rate': [0.1, 0.01, 0.001],\n",
    "    'iterations': [100, 200, 500, 1000],\n",
    "}\n",
    "grid_search_custom(model, param_grid, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uGA1skpJN_i3",
    "outputId": "206c5b0d-45c6-4a85-d4de-a0d289a64973"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0.01, 1): (<__main__.LogisticRegressionNewton at 0x10ff21be0>,\n",
       "  np.float64(0.7722222222222221)),\n",
       " (0.01, 3): (<__main__.LogisticRegressionNewton at 0x10ff21be0>,\n",
       "  np.float64(0.7055555555555556)),\n",
       " (0.01, 10): (<__main__.LogisticRegressionNewton at 0x10ff21be0>,\n",
       "  np.float64(0.7555555555555555)),\n",
       " (0.001, 1): (<__main__.LogisticRegressionNewton at 0x10ff21be0>,\n",
       "  np.float64(0.7055555555555555)),\n",
       " (0.001, 3): (<__main__.LogisticRegressionNewton at 0x10ff21be0>,\n",
       "  np.float64(0.711111111111111)),\n",
       " (0.001, 10): (<__main__.LogisticRegressionNewton at 0x10ff21be0>,\n",
       "  np.float64(0.8055555555555556))}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegressionNewton()\n",
    "param_grid = {\n",
    "    'lerning_rate': [ 0.01, 0.001],\n",
    "    'iterations': [1 ,3 ,10],\n",
    "}\n",
    "grid_search_custom(model, param_grid, x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "0VpNLapX83aq"
   },
   "outputs": [],
   "source": [
    "#task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NA-jrKLpAHDC",
    "outputId": "423a8891-4d9c-451e-cdb9-aa1d53f13305"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pl/zhkjndkn2k169_3t63dgk06m0000gn/T/ipykernel_10008/3618153951.py:9: RuntimeWarning: overflow encountered in exp\n",
      "  self.sigmoid = lambda z : 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6722222222222223\n",
      "GD accuracy: 0.6065573770491803, precision: 0.4375, recall: 0.7, F1-Score: 0.5384615384615384\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(x, y)\n",
    "param_grid = {\n",
    "    'lerning_rate': [0.1, 0.01, 0.001],\n",
    "    'iterations': [100, 200, 500, 1000],\n",
    "}\n",
    "scores = grid_search_custom(model, param_grid, x, y)\n",
    "best_model, score = max(scores.values(), key = lambda x: x[1])\n",
    "print(score)\n",
    "print(\"GD accuracy: %s, precision: %s, recall: %s, F1-Score: %s\" %\n",
    " (best_model.accuracy(x,y), best_model.precision(x,y), best_model.recall(x,y), best_model.f1_score(x,y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yRVPSyI6BSD2",
    "outputId": "1066c2a2-799e-4a0e-ab74-cc0914dd99b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7555555555555555\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegressionNewton()\n",
    "param_grid = {\n",
    "    'iterations': [10, 30, 50, 100]\n",
    "}\n",
    "scores = grid_search_custom(model, param_grid, x, y)\n",
    "best_model, score = max(scores.values(), key = lambda x: x[1])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SvMov6WtBA9P",
    "outputId": "7a06f1b1-4883-4922-9492-5afd7d5cf450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7833333333333334\n",
      "GD accuracy: 0.8306010928961749, precision: 0.7543859649122807, recall: 0.7166666666666667, F1-Score: 0.735042735042735\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegressionNewton()\n",
    "model.fit(x, y)\n",
    "param_grid = {\n",
    "    'iterations': [10, 30, 50, 100]\n",
    "}\n",
    "scores = grid_search_custom(model, param_grid, x, y)\n",
    "best_model, score = max(scores.values(), key = lambda x: x[1])\n",
    "print(score)\n",
    "print(\"GD accuracy: %s, precision: %s, recall: %s, F1-Score: %s\" %\n",
    " (best_model.accuracy(x,y), best_model.precision(x,y), best_model.recall(x,y), best_model.f1_score(x,y)))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
